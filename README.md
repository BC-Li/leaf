 <h1 align="center">Paper Reading</h1>

<div align="center"> 
  This repo contains my paper reading notes on deep learning.
  Check the notes at https://bc-li.github.io/paperreading.
</div>

## Paper reading notes
### PHASE #1
| Title                                                        | Field | Time | Report link                       | Time I started | Status      |
| ------------------------------------------------------------ | ----- | ---- | --------------------------------- | ----------- | ----------- |
| [ICCV 2015] Learning Deconvolution Network for Semantic Segmentation | VISION   | 2015 | https://bc-li.github.io/paper/deconvnet | 2021/5/17 | Done |
| [NeurIPS 2017] Attention Is All You Need                     | NLP   | 2017 | https://bc-li.github.io/paper/transformer | 2021/12/11 | Done |
| [NAACL 2019] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | NLP   | 2018 | https://bc-li.github.io/paper/bert         | 2021/12/15 | Done       |
| [NeurIPS 2014] Sequence to Sequence Learning with Neural Networks | NLP   | 2014 | https://bc-li.github.io/paper/seq2seq      | 2022/1/21 | Done  |
| [ICLR 2018] Non-Autoregressive Neural Machine Translation | NLP | 2018 | https://bc-li.github.io/paper/nonauto | 2022/1/24 | Done |
| [ICLR 2019] Parameter-Efficient Transfer Learning for NLP | NLP | 2019 | https://bc-li.github.io/paper/petl | 2022/2/2 | Done |
| [ICLR 2018] Unsupervised Neural Machine Translation | NLP | 2018 | https://bc-li.github.io/paper/unsupervised-NMT | 2022/2/4 | Done |

### PHASE #1.5 

| Title                  | Field  | Time      | Report link                       | Time I started | Status  |
| ---------------------- | ------ | --------- | --------------------------------- | -------------- | ------- |
| Classic CNN structures (LeNet to DenseNet) | VISION | 1998-2017 | https://bc-li.github.io/paper/cnn | 2022/2/25      | Done |
| MobileNets series [V1 to V3] | VISION   | 2017 |  https://bc-li.github.io/paper/mobilenets | 2022/3/10 | Done |
| SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size | VISION   | 2016 |  https://bc-li.github.io/paper/SqueezeNet | 2022/3/10 | Pending |
> Classic CNN structures: 对近年来比较经典的 CNN 架构类型做了小结，并基于 [d2l.ai](d2l.ai) 提供代码在 FASHION 数据集上进行训练，做了简单尝试。
 
### PHASE #2

| Title                                                        | Field | Time | Report link                       | Time I started | Status      |
| ------------------------------------------------------------ | ----- | ---- | --------------------------------- | ----------- | ----------- |
| [NeurIPS 2019] Levenshtein Transformer | NLP | 2019 | https://bc-li.github.io/paper/lt | 2022/2/15 | Pending |


### Stack

| Title                                                        | Field | Time | Report link                       | Time I started | Status      |
| ------------------------------------------------------------ | ----- | ---- | --------------------------------- | ----------- | ----------- |
| [SCTS 2020] Pre-trained Models for Natural Language Processing: A Survey | NLP   | 2020 | N/A | N/A | N/A |

> 写 blog 的时候如未特殊说明则为从约为零基础开始。在 blog post 中我会把我为了理解文中一些比较 specific 的概念找到的相对容易理解的原出处贴到文中，方便查阅，且不再重复阐述。


## Acknowledgements

https://github.com/mli/paper-reading

https://www.deeplearningbook.org/

